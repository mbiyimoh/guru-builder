# Bug Fix Synthesis: Board Visibility & Audit Trail Extraction

**Purpose**: Fix two critical implementation issues in your guru self-assessment system that deviate from the Backgammon Guru reference implementation.

---

## Issue #1: Guru Cannot See Board Position

### The Problem

The guru says it cannot see the board position and dice roll, which means the **drill context is NOT being injected into the system prompt**.

### Root Cause

In your implementation, you're likely passing the drill context to the API route but NOT actually including it in the system prompt that gets sent to the AI model. The AI model only sees the user's question, not the board state.

### The Correct Pattern (from Backgammon Guru)

**The drill context MUST be formatted as text and appended to the system prompt BEFORE sending to the AI.**

```typescript
// app/api/chat/route.ts - Lines 46-64
if (mode === 'drill') {
  // 1. Load base context layers
  const contextResult = await composeContextWithMetadata(projectId, layerIds)
  systemPrompt = contextResult.prompt  // Base knowledge

  // 2. CRITICAL: Append drill-specific prompt with board position
  if (drillContext) {
    const drillPrompt = composeDrillSystemPrompt(drillContext)
    systemPrompt += '\n\n' + drillPrompt  // <-- THIS IS THE KEY LINE
  }
}

// 3. Build messages array WITH system prompt containing drill context
const messages = [
  { role: 'system' as const, content: systemPrompt },  // AI sees board here
  ...coreMessages,  // User's question
]

// 4. Send to AI - it now has full visibility into position
const result = streamText({ model, messages, ... })
```

### How composeDrillSystemPrompt() Works

This function converts the drill object into a **text representation** the AI can read:

```typescript
// lib/contextComposer.ts - Lines 103-176
export function composeDrillSystemPrompt(drillContext: DrillContext): string {
  const { drill, hintsUsedCount } = drillContext
  const boardSummary = drill.boardSetup.summary

  return `
---

# DRILL MODE ACTIVE

You are helping the user practice this specific position:

**Position**: ${boardSummary}
**To Play**: ${drill.toPlay}
**Roll**: ${drill.roll.join('-')}
**Question**: ${drill.question}

**Core Principle**: ${drill.principle}

**Available Moves**:
${drill.options
  .map((opt, idx) => `${idx + 1}. ${opt.move} ${opt.isCorrect ? '✓ CORRECT' : '✗ INCORRECT'}
   ${opt.explanation}`)
  .join('\n\n')}

---

## Your Role

When user asks about this position:
- You can see the board state above
- Reference the specific position in your answers
- Use the principle to guide your explanation
`.trim()
}
```

### What You Need to Fix

1. **Create a `composeDrillSystemPrompt()` function** that formats your quiz/drill data into text:

```typescript
// lib/contextComposer.ts (create this file)
export function composeDrillSystemPrompt(drillContext) {
  const { drill } = drillContext

  return `
# ASSESSMENT POSITION

**Position Setup**: ${drill.boardSetup.summary}
**To Play**: ${drill.toPlay}
**Roll**: ${drill.roll.join('-')}
**Question**: ${drill.question}

**Candidate Moves to Evaluate**:
${drill.candidateMoves.map((move, i) => `${i + 1}. ${move}`).join('\n')}

---

IMPORTANT: You CAN see the board position above. Use this information to analyze the position and recommend the best move.
`
}
```

2. **Call this function in your API route** and append to system prompt:

```typescript
// app/api/chat/route.ts
const systemPrompt = await composeBaseContext()

if (mode === 'drill' && drillContext) {
  // THIS IS CRITICAL - append drill context to system prompt
  const drillPrompt = composeDrillSystemPrompt(drillContext)
  systemPrompt += '\n\n' + drillPrompt
}

// Now the AI model will see the board position in its system prompt
const messages = [
  { role: 'system', content: systemPrompt },  // Contains board position
  ...userMessages,
]
```

### Verification

After fixing, the AI should be able to say things like:
- "Looking at the position where you have 2 checkers on the 24-point..."
- "With a roll of 3-1, you can make the 5-point by playing 8/5, 6/5..."
- "This position shows a typical opening setup where..."

If it still says "I cannot see the board", the system prompt is NOT being constructed correctly.

---

## Issue #2: Audit Trail Generated as LLM Text

### The Problem

The context audit information is being **generated by the LLM as part of its response text**, instead of being **extracted from the Claude API response metadata**.

### Root Cause

You're likely prompting the AI to output its own "audit" information, which makes it fabricate reasoning traces and token counts. This is NOT how it should work.

### The Correct Pattern (from Backgammon Guru)

**The audit trail is EXTRACTED from Claude's actual API response, not generated as text.**

Claude's API provides:
1. `result.reasoning` - The actual extended thinking traces (what Claude thought about)
2. `result.usage` - The actual token counts (prompt, completion, total)

These are **separate promises** that resolve AFTER the AI response completes, and we capture this **real data** from the API, not generated text.

```typescript
// app/api/chat/route.ts - Lines 122-138
const result = streamText({
  model,
  messages,
  providerOptions: {
    anthropic: {
      thinking: {
        type: 'enabled',
        budgetTokens: 5000,  // Claude will think for up to 5000 tokens
      },
    },
  },
})

// EXTRACT actual reasoning and usage from Claude's API response
Promise.all([
  result.reasoning,  // Promise<ReasoningOutput[]> - ACTUAL thinking traces
  result.usage,      // Promise<Usage> - ACTUAL token counts
]).then(([reasoning, usage]) => {
  // reasoning is Claude's ACTUAL internal thinking, not generated text
  const reasoningText = reasoning?.map(r => r.text).join('\n\n')

  // usage has ACTUAL token counts from the API
  console.log('Prompt tokens:', usage.inputTokens)
  console.log('Completion tokens:', usage.outputTokens)

  // Store this REAL data in audit trail
  updateAuditTrailWithData({
    messageId,
    model: 'claude-3-7-sonnet-20250219',
    usage,
    reasoning: reasoningText,
  })
})
```

### The Key Distinction

**WRONG (what you're doing):**
```typescript
// Prompting AI to generate audit info as text
const systemPrompt = `
After answering, include:
## Context Audit
- Reasoning: [your thinking process]
- Tokens: [estimate]
- Cost: [estimate]
`
// Result: AI fabricates this information
```

**CORRECT (what you should do):**
```typescript
// 1. Enable extended thinking in provider options
const result = streamText({
  model: anthropic('claude-3-7-sonnet-20250219'),
  messages,  // System prompt + user messages (NO audit instructions)
  providerOptions: {
    anthropic: {
      thinking: {
        type: 'enabled',
        budgetTokens: 5000,
      },
    },
  },
})

// 2. Extract REAL data from API response
result.reasoning.then(reasoning => {
  // This is Claude's ACTUAL thinking, captured by the API
  console.log('Real reasoning traces:', reasoning)
})

result.usage.then(usage => {
  // These are ACTUAL counts from the API, not estimates
  console.log('Real token usage:', usage)
})

// 3. Calculate costs from REAL usage
const costs = {
  prompt: (usage.inputTokens / 1_000_000) * 3.00,    // Claude Sonnet pricing
  completion: (usage.outputTokens / 1_000_000) * 15.00,
}

// 4. Store in separate data structure (NOT in AI response)
storeAuditTrail({
  messageId,
  reasoning: realReasoningTraces,
  tokens: realUsageCounts,
  cost: calculatedCosts,
})

// 5. Display in UI via separate modal/component
// Frontend fetches audit trail by messageId
// Shows REAL data, not AI-generated text
```

### What You Need to Fix

1. **Remove any audit instructions from your system prompt.** The AI should NOT output audit information.

2. **Enable Claude's extended thinking** to capture reasoning:

```typescript
// In your API route
const result = streamText({
  model: anthropic('claude-3-7-sonnet-20250219'),
  messages,
  providerOptions: {
    anthropic: {
      thinking: {
        type: 'enabled',
        budgetTokens: 5000,
      },
    },
  },
})
```

3. **Extract reasoning and usage from the result object**:

```typescript
// These are promises that resolve after streaming completes
const reasoning = await result.reasoning  // Claude's actual thinking
const usage = await result.usage          // Actual token counts

// reasoning is an array of ReasoningOutput objects with text
const thinkingTraces = reasoning?.map(r => r.text).join('\n\n')

// usage has actual numbers
const { inputTokens, outputTokens, totalTokens } = usage
```

4. **Store in separate data structure** (not in AI response):

```typescript
// lib/auditStore.ts
const auditStore = new Map<string, AuditTrail>()

export function storeAuditTrail(trail: AuditTrail) {
  auditStore.set(trail.messageId, trail)
}

export function getAuditTrail(messageId: string) {
  return auditStore.get(messageId)
}
```

5. **Create API endpoint to retrieve audit data**:

```typescript
// app/api/audit/[messageId]/route.ts
export async function GET(req, { params }) {
  const { messageId } = params
  const auditTrail = getAuditTrail(messageId)

  if (!auditTrail) {
    return NextResponse.json({ error: 'Not found' }, { status: 404 })
  }

  return NextResponse.json({ auditTrail })
}
```

6. **Display in separate UI component** (modal/drawer):

```tsx
// components/ContextAuditModal.tsx
function ContextAuditModal({ messageId, isOpen, onClose }) {
  const [auditTrail, setAuditTrail] = useState(null)

  useEffect(() => {
    if (isOpen && messageId) {
      fetch(`/api/audit/${messageId}`)
        .then(res => res.json())
        .then(data => setAuditTrail(data.auditTrail))
    }
  }, [isOpen, messageId])

  return (
    <Modal isOpen={isOpen} onClose={onClose}>
      <h2>Context Audit Trail</h2>

      <section>
        <h3>Model</h3>
        <p>{auditTrail?.model}</p>
      </section>

      <section>
        <h3>Token Usage</h3>
        <p>Prompt: {auditTrail?.tokens.prompt}</p>
        <p>Completion: {auditTrail?.tokens.completion}</p>
        <p>Total: {auditTrail?.tokens.total}</p>
      </section>

      <section>
        <h3>Cost</h3>
        <p>Prompt: ${auditTrail?.cost.prompt.toFixed(6)}</p>
        <p>Completion: ${auditTrail?.cost.completion.toFixed(6)}</p>
        <p>Total: ${auditTrail?.cost.total.toFixed(6)}</p>
      </section>

      <section>
        <h3>Reasoning Traces</h3>
        <pre>{auditTrail?.reasoning?.join('\n\n')}</pre>
      </section>

      <section>
        <h3>Context Layers Used</h3>
        <ul>
          {auditTrail?.contextLayers.map(layer => (
            <li key={layer.id}>{layer.name} ({layer.contentLength} chars)</li>
          ))}
        </ul>
      </section>
    </Modal>
  )
}
```

### Verification

After fixing:
1. The AI response should contain ONLY the answer to the user's question (no audit info)
2. Click "View Context Audit" button to open separate modal
3. Modal shows REAL data:
   - Reasoning traces: Claude's actual internal thinking (varies each time)
   - Token counts: Exact numbers from API (e.g., 1,234 prompt + 567 completion)
   - Costs: Calculated from real usage (e.g., $0.00370 + $0.00851)
   - Context layers: What was actually in the system prompt

**Red flags that you're still doing it wrong:**
- Audit info appears inline with AI response text
- Token counts are round numbers (1000, 500) instead of exact (1,234)
- Reasoning looks too "clean" or structured (real reasoning is messy thinking)
- Costs are estimates instead of precise calculations

---

## Complete Implementation Pattern

Here's the full flow from the Backgammon Guru project:

### 1. Frontend sends request with drill context

```typescript
// components/chat/BackgammonChat.tsx
sendMessage(
  { text: userInput },
  {
    body: {
      projectId: 'default-project',
      mode: 'drill',
      drillContext: {
        drillId: 1,
        moduleId: 1,
        drill: {
          boardSetup: { /* position data */ },
          toPlay: 'black',
          roll: [3, 1],
          question: 'What is the best move?',
          options: [/* move options */],
          principle: 'Core teaching concept',
          hintsAvailable: [/* hints */],
        },
        hintsUsedCount: 0,
      },
    },
  }
)
```

### 2. Backend composes system prompt WITH drill context

```typescript
// app/api/chat/route.ts
const { mode, drillContext } = body

// Build base system prompt
let systemPrompt = await composeBaseContext()

// INJECT DRILL CONTEXT INTO SYSTEM PROMPT
if (mode === 'drill' && drillContext) {
  const drillPrompt = composeDrillSystemPrompt(drillContext)
  systemPrompt += '\n\n' + drillPrompt  // AI now sees board position
}

// Build messages with system prompt
const messages = [
  { role: 'system', content: systemPrompt },
  ...convertToCoreMessages(uiMessages),
]
```

### 3. Backend enables extended thinking for Claude

```typescript
// Stream with extended thinking enabled
const result = streamText({
  model: anthropic('claude-3-7-sonnet-20250219'),
  messages,
  providerOptions: {
    anthropic: {
      thinking: {
        type: 'enabled',
        budgetTokens: 5000,
      },
    },
  },
})
```

### 4. Backend extracts REAL audit data from API response

```typescript
// Generate messageId for correlation
const messageId = crypto.randomUUID()

// Create placeholder immediately (prevents race condition)
createPlaceholderAuditTrail({
  messageId,
  model: 'claude-3-7-sonnet-20250219',
  contextLayers: [/* layers used */],
})

// Extract REAL data when available (async)
Promise.all([result.reasoning, result.usage])
  .then(([reasoning, usage]) => {
    const reasoningText = reasoning?.map(r => r.text).join('\n\n')

    updateAuditTrailWithData({
      messageId,
      model: 'claude-3-7-sonnet-20250219',
      usage,  // REAL token counts
      reasoning: reasoningText,  // REAL thinking traces
    })
  })
```

### 5. Backend returns response with messageId

```typescript
return result.toUIMessageStreamResponse({
  headers: {
    'x-message-id': messageId,
  },
})
```

### 6. Frontend extracts messageId and displays audit button

```typescript
// Extract messageId from response header
onResponse: (response) => {
  const messageId = response.headers.get('x-message-id')
  pendingMessageIdRef.current = messageId
}

// Associate with message when complete
onFinish: ({ message }) => {
  setMessageMetadata(prev => ({
    ...prev,
    [message.id]: { messageId: pendingMessageIdRef.current }
  }))
}

// Render audit button if metadata exists
{messageMetadata[message.id] && (
  <button onClick={() => openAuditModal(messageMetadata[message.id].messageId)}>
    View Context Audit
  </button>
)}
```

### 7. User clicks button, modal fetches REAL audit data

```typescript
// Modal fetches from API endpoint
const auditTrail = await fetch(`/api/audit/${messageId}`).then(r => r.json())

// Displays REAL data (not AI-generated text)
<pre>{auditTrail.reasoning}</pre>
<p>Tokens: {auditTrail.tokens.total}</p>
<p>Cost: ${auditTrail.cost.total.toFixed(4)}</p>
```

---

## Summary

**Issue #1 Fix**: Inject drill context into system prompt via `composeDrillSystemPrompt()` so the AI can "see" the board position.

**Issue #2 Fix**: Extract reasoning and usage from Claude's API response metadata (real data), store separately, and display in modal - NOT generated as LLM text output.

The key principle: **Audit data comes FROM the AI's API response metadata, not AS part of the AI's text output.**
